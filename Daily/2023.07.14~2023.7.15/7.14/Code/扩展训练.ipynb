{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## RBF神经网络"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "看了源码，但是没有自己搭建，有点长....而且这个网络相对比较好理解\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.losses import MSE\n",
    "import matplotlib.pyplot as pl"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## kaggle竞赛框架 ----里面的卷积神经网络还在设计中（还会改进）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 182] 操作系统无法运行 %1。 Error loading \"D:\\Anaconda3\\envs\\pytest\\lib\\site-packages\\torch\\lib\\nvfuser_codegen.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dataset\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\pytest\\lib\\site-packages\\torch\\__init__.py:122\u001B[0m\n\u001B[0;32m    120\u001B[0m     err \u001B[38;5;241m=\u001B[39m ctypes\u001B[38;5;241m.\u001B[39mWinError(last_error)\n\u001B[0;32m    121\u001B[0m     err\u001B[38;5;241m.\u001B[39mstrerror \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m Error loading \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdll\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m or one of its dependencies.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    124\u001B[0m     is_loaded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mOSError\u001B[0m: [WinError 182] 操作系统无法运行 %1。 Error loading \"D:\\Anaconda3\\envs\\pytest\\lib\\site-packages\\torch\\lib\\nvfuser_codegen.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import Sequential, Conv2d, MaxPool2d, Flatten, Linear\n",
    "\n",
    "\n",
    "# 定义解析函数\n",
    "def parse_example(example_proto):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'target': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image_name': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    # 解析Example对象\n",
    "    parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "    # 检查特征名称\n",
    "    if 'image_name' not in parsed_features:\n",
    "        raise ValueError(\"The feature 'image_name' is missing from the TFRecord file.\")\n",
    "\n",
    "    # 解码JPEG图像等\n",
    "    image = tf.image.decode_jpeg(parsed_features['image'], channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    target = parsed_features['target']\n",
    "    image_name = parsed_features['image_name']\n",
    "\n",
    "    ##返回值\n",
    "    return image, target, image_name\n",
    "\n",
    "# 解析文件中的每个Example\n",
    "Image, Target, Image_name = [], [], []\n",
    "\n",
    "# 文件路径\n",
    "file_path = './ld_train00-1338.tfrec'\n",
    "\n",
    "# 创建TFRecordDataset对象\n",
    "dataset = tf.data.TFRecordDataset(file_path)\n",
    "\n",
    "# 解析\n",
    "parsed_dataset = dataset.map(parse_example)\n",
    "\n",
    "# 遍历每个Example并使用数据\n",
    "for image, target, image_name in parsed_dataset:\n",
    "    # 在这里使用解析出来的特征\n",
    "    ##print(f\"Image shape: {image.shape}, Target: {target.numpy()}, Image Name: {image_name.numpy()}\")\n",
    "    Image.append(image)\n",
    "    Target.append(target)\n",
    "    Image_name.append(image_name)\n",
    "\n",
    "for n in range(len(Image)):\n",
    "    Image[n] = Image[n].numpy()\n",
    "    Image[n] = torch.tensor(Image[n])\n",
    "    Image[n] = Image[n].reshape([3,512,512])\n",
    "    Target[n] = Target[n].numpy()\n",
    "    Target[n] = torch.tensor(Target[n])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 构造数据集\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mCreateDataset\u001B[39;00m(\u001B[43mDataset\u001B[49m):\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, data, labels):\n\u001B[0;32m      4\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m data\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# 构造数据集\n",
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "\n",
    "dataset = CreateDataset(Image, Target)\n",
    "batch_size = 64  ##构建批次\n",
    "dataset = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m file_path_test \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/kaggle/input/cassava-leaf-disease-classification/train_tfrecords/ld_train15-1327.tfrec\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 2\u001B[0m dataset_test \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mTFRecordDataset(file_path_test)\n\u001B[0;32m      3\u001B[0m parsed_dataset \u001B[38;5;241m=\u001B[39m dataset_test\u001B[38;5;241m.\u001B[39mmap(parse_example)\n\u001B[0;32m      4\u001B[0m Image1, Target1, Image_name1 \u001B[38;5;241m=\u001B[39m [], [], []\n",
      "\u001B[1;31mNameError\u001B[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "file_path_test = './ld_train15-1327.tfrec'\n",
    "dataset_test = tf.data.TFRecordDataset(file_path_test)\n",
    "parsed_dataset = dataset_test.map(parse_example)\n",
    "Image1, Target1, Image_name1 = [], [], []\n",
    "for image, target, image_name in parsed_dataset:\n",
    "        # 在这里使用解析出来的特征\n",
    "        ##print(f\"Image shape: {image.shape}, Target: {target.numpy()}, Image Name: {image_name.numpy()}\")\n",
    "        Image1.append(image)\n",
    "        Target1.append(target)\n",
    "        Image_name1.append(image_name)\n",
    "for n in range(len(Image1)):\n",
    "    Image1[n] = Image[n].numpy()\n",
    "    Image1[n] = torch.tensor(Image1[n])\n",
    "    Image1[n] = Image[n].reshape([3,512,512])\n",
    "    Target1[n] = Target[n].numpy()\n",
    "    Target1[n] = torch.tensor(Target[n])\n",
    "dataset_test = CreateDataset(Image1, Target1)\n",
    "dataset_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 模型\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mTudui\u001B[39;00m(\u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mModule):\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m      4\u001B[0m         \u001B[38;5;28msuper\u001B[39m(Tudui,\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# 模型\n",
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tudui,self).__init__()\n",
    "        self.model1 = Sequential(\n",
    "            MaxPool2d(2),\n",
    "            Conv2d(3,64,5,1,padding=2),\n",
    "            MaxPool2d(4),\n",
    "            Conv2d(64,64,5,1,padding=2),\n",
    "            MaxPool2d(4),\n",
    "            Conv2d(64,64,5,1,padding=2),\n",
    "            MaxPool2d(2),\n",
    "            Flatten(),\n",
    "            Linear(4096,512))\n",
    "        self.output_model1 = Linear(512,64)\n",
    "        self.output_model2 = Linear(64,5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.model1(x)\n",
    "        x = x.relu()\n",
    "        x = self.output_model1(x)\n",
    "        x = x.relu()\n",
    "        x = self.output_model2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## cuba设置\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "## 模型建立\n",
    "tudui = Tudui()\n",
    "tudui = tudui.to(device)\n",
    "\n",
    "## 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "##优化器\n",
    "optimizer = torch.optim.SGD(tudui.parameters(),lr = 0.01)\n",
    "\n",
    "##初始值设置\n",
    "total_train_step = 0\n",
    "total_test_step = 0\n",
    "epoch = 10\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"---------------第{}轮的开始-------------\".format(i+1))\n",
    "\n",
    "    for data in dataset:\n",
    "        imgs,targets = data\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = tudui(imgs)\n",
    "        loss = loss_fn(outputs,targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_step = total_train_step+1\n",
    "        if total_train_step %100 ==0:\n",
    "            print(\"训练次数：{}，Loss:{}\".format(total_train_step,loss))\n",
    "\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataset_test:\n",
    "            imgs,targets = data\n",
    "            imgs = imgs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = tudui(imgs)\n",
    "            loss = loss_fn(outputs,targets)\n",
    "            total_test_loss = total_test_step + loss.item()\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "    print(\"整体测试集上的loss：{}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率：{}\".format(total_accuracy/test_data_size))\n",
    "    total_test_step += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
